<head><meta name="google-site-verification" content="fdyq3CHPPN3-FQjd51PCUT7FsuE-HMECoHXx_Vs0QBg" /></head>

# mlvoca.com

## A free LLM API

This API provides access to a publicly hosted `/api/generate` endpoint based on the Ollama API, enabling text generation through various models.

<br>
<p align="center">
    <img src="https://github.com/mlvoca/mlvoca.com/blob/main/images/mlvoca_image2.png?raw=true" style="width: 70%;">
</p>

## Base URL
```
https://mlvoca.com
```

## Endpoint: Generate a Completion

### **POST** `/api/generate`

Generates a response based on a given prompt using a specified model. It supports both streaming and single-response generation.

### Available Models
- TinyLlama
- DeepSeek R1 (1.5b)

### Request Parameters

Accepts the following parameters:

- **`model` (required)** - The model name used for generation (can be `"tinyllama"` or `"deepseek-r1:1.5b"`).
- **`prompt` (required)** - The input prompt for text generation.
- **`suffix`** - Text appended after the model response.
- **`format`** - Specifies the response format (`"json"` or JSON schema).
- **`options`** - Additional model parameters (e.g., `"temperature"`).
- **`system`** - System message override.
- **`template`** - Custom prompt template.
- **`stream`** - If `false`, returns a single response instead of a stream.
- **`raw`** - If `true`, bypasses formatting and applies the full prompt.
- **`keep_alive`** - Duration the model remains loaded in memory (default: `"5m"`).

### Example Usage

#### Shell commands for API requests:
Shell command with streaming enabled:
```sh
curl -X POST https://mlvoca.com/api/generate -d '{
  "model": "deepseek-r1:1.5b",
  "prompt": "Why is the sky blue?"
}'
```
Shell command without streaming:
```sh
curl -X POST https://mlvoca.com/api/generate -d '{
  "model": "tinyllama",
  "prompt": "Why is the sky blue?",
  "stream": false
}'
```

### Example Responses

#### Streaming response:
```
{"model":"deepseek-r1:1.5b","created_at":"2025-05-09T21:27:21.057589936Z","response":"\u003cthink\u003e","done":false}
{"model":"deepseek-r1:1.5b","created_at":"2025-05-09T21:27:21.105047151Z","response":"\n","done":false}
{"model":"deepseek-r1:1.5b","created_at":"2025-05-09T21:27:21.153911631Z","response":"Okay","done":false}
{"model":"deepseek-r1:1.5b","created_at":"2025-05-09T21:27:21.205618283Z","response":",","done":false}
{"model":"deepseek-r1:1.5b","created_at":"2025-05-09T21:27:21.255770562Z","response":" so","done":false}
{"model":"deepseek-r1:1.5b","created_at":"2025-05-09T21:27:21.30646764Z","response":" I","done":false}
{"model":"deepseek-r1:1.5b","created_at":"2025-05-09T21:27:21.35307409Z","response":" need","done":false}
{"model":"deepseek-r1:1.5b","created_at":"2025-05-09T21:27:21.403763503Z","response":" to","done":false}
{"model":"deepseek-r1:1.5b","created_at":"2025-05-09T21:27:21.455158427Z","response":" explain","done":false}
{"model":"deepseek-r1:1.5b","created_at":"2025-05-09T21:27:21.509438012Z","response":" why","done":false}
{"model":"deepseek-r1:1.5b","created_at":"2025-05-09T21:27:21.562936885Z","response":" the","done":false}
{"model":"deepseek-r1:1.5b","created_at":"2025-05-09T21:27:21.615074831Z","response":" sky","done":false}
{"model":"deepseek-r1:1.5b","created_at":"2025-05-09T21:27:21.669268845Z","response":" looks","done":false}
{"model":"deepseek-r1:1.5b","created_at":"2025-05-09T21:27:21.723751905Z","response":" blue","done":false}
...
```

#### Response without streaming:
```
{
  "model": "tinyllama",
  "created_at": "2025-05-09T19:34:00Z",
  "response": "The sky is blue because of Rayleigh scattering.",
  "done": true
  ...
}
```

---

## Notes
- The endpoint currently works without any kind of rate limit or API key. Therefore, it can be used for free without token/call limits.
- The hardware resources are limited. Therefore, responses might be a little slower sometimes, especially during times of high usage.
- We encourage scientific use of this API. Researchers, educators, and students from universities or educational institutions are encouraged to utilize this resource for scientific purposes. Please reach out to mlvoca@protonmail.com if you are planning to use the API in such a way.
- Commercial use of this api is not allowed. If you are planning on using this API for your business, please contact mlvoca@protonmail.com.

## Disclaimer
The API and related services provided herein are made available "as is" and "as available" without any warranties or guarantees, express or implied. The provider of this API (hereinafter referred to as "the Host") does not assume any liability for the accuracy, reliability, completeness, or usefulness of the outputs generated by large language models (LLMs) accessed through this API.

Users acknowledge and agree that:

The Host shall not be responsible for any actions, decisions, or consequences arising from the use of this API or any outputs generated by LLMs.

The Host disclaims any liability for direct, indirect, incidental, consequential, or special damages, including but not limited to loss of data, business disruption, or reputational harm, even if advised of the possibility of such damages.

Users are solely responsible for evaluating the appropriateness, legality, and applicability of the APIâ€™s outputs in their respective contexts.

The use of this API does not establish any form of client-provider, advisor, or fiduciary relationship.

By accessing and using this API, users agree to the terms set forth in this disclaimer and waive any claims against the Host related to its usage.
